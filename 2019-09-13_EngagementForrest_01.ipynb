{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete.\n"
     ]
    }
   ],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "#from fastai.data_block import *\n",
    "\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn import metrics\n",
    "print('Setup Complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>delta-TP9</th>\n",
       "      <th>delta-AF7</th>\n",
       "      <th>delta-AF8</th>\n",
       "      <th>delta-TP10</th>\n",
       "      <th>theta-TP9</th>\n",
       "      <th>theta-AF7</th>\n",
       "      <th>theta-AF8</th>\n",
       "      <th>theta-TP10</th>\n",
       "      <th>alpha-TP9</th>\n",
       "      <th>alpha-AF7</th>\n",
       "      <th>alpha-AF8</th>\n",
       "      <th>alpha-TP10</th>\n",
       "      <th>beta-TP9</th>\n",
       "      <th>beta-AF7</th>\n",
       "      <th>beta-AF8</th>\n",
       "      <th>beta-TP10</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213514</td>\n",
       "      <td>2.399008</td>\n",
       "      <td>2.407957</td>\n",
       "      <td>0.393249</td>\n",
       "      <td>0.534341</td>\n",
       "      <td>0.836858</td>\n",
       "      <td>1.424246</td>\n",
       "      <td>0.657038</td>\n",
       "      <td>-0.467993</td>\n",
       "      <td>0.814466</td>\n",
       "      <td>0.643818</td>\n",
       "      <td>0.098162</td>\n",
       "      <td>-1.078152</td>\n",
       "      <td>0.973413</td>\n",
       "      <td>-0.246633</td>\n",
       "      <td>-0.845306</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.274502</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>1.514658</td>\n",
       "      <td>0.496492</td>\n",
       "      <td>0.181557</td>\n",
       "      <td>-0.012250</td>\n",
       "      <td>0.626624</td>\n",
       "      <td>0.175984</td>\n",
       "      <td>-0.906638</td>\n",
       "      <td>0.832131</td>\n",
       "      <td>-0.332070</td>\n",
       "      <td>0.329700</td>\n",
       "      <td>-1.247669</td>\n",
       "      <td>-0.714387</td>\n",
       "      <td>-1.326559</td>\n",
       "      <td>-1.020843</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069119</td>\n",
       "      <td>0.729497</td>\n",
       "      <td>1.285416</td>\n",
       "      <td>0.097301</td>\n",
       "      <td>-0.467740</td>\n",
       "      <td>0.760934</td>\n",
       "      <td>-0.579900</td>\n",
       "      <td>-0.558739</td>\n",
       "      <td>-1.301238</td>\n",
       "      <td>-0.218394</td>\n",
       "      <td>-0.055393</td>\n",
       "      <td>0.249293</td>\n",
       "      <td>-1.385920</td>\n",
       "      <td>0.074558</td>\n",
       "      <td>-1.289886</td>\n",
       "      <td>-0.749937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.480663</td>\n",
       "      <td>1.615700</td>\n",
       "      <td>-0.158431</td>\n",
       "      <td>-1.007132</td>\n",
       "      <td>1.443319</td>\n",
       "      <td>-0.212008</td>\n",
       "      <td>-0.532355</td>\n",
       "      <td>-1.779209</td>\n",
       "      <td>-1.227202</td>\n",
       "      <td>0.353502</td>\n",
       "      <td>-0.087381</td>\n",
       "      <td>-0.508575</td>\n",
       "      <td>-0.075375</td>\n",
       "      <td>-0.891891</td>\n",
       "      <td>-0.433480</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.210349</td>\n",
       "      <td>0.119917</td>\n",
       "      <td>1.832329</td>\n",
       "      <td>-0.231751</td>\n",
       "      <td>-0.616393</td>\n",
       "      <td>1.045143</td>\n",
       "      <td>-0.127250</td>\n",
       "      <td>-0.344241</td>\n",
       "      <td>-1.137883</td>\n",
       "      <td>-1.686370</td>\n",
       "      <td>0.923469</td>\n",
       "      <td>-0.147632</td>\n",
       "      <td>0.351424</td>\n",
       "      <td>-1.111880</td>\n",
       "      <td>-1.395548</td>\n",
       "      <td>-0.580706</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  delta-TP9 delta-AF7 delta-AF8 delta-TP10 theta-TP9 theta-AF7 theta-AF8  \\\n",
       "0  0.213514  2.399008  2.407957   0.393249  0.534341  0.836858  1.424246   \n",
       "1  0.274502  0.921714  1.514658   0.496492  0.181557 -0.012250  0.626624   \n",
       "2  0.069119  0.729497  1.285416   0.097301 -0.467740  0.760934 -0.579900   \n",
       "3  0.003141  0.480663  1.615700  -0.158431 -1.007132  1.443319 -0.212008   \n",
       "4 -0.210349  0.119917  1.832329  -0.231751 -0.616393  1.045143 -0.127250   \n",
       "\n",
       "  theta-TP10 alpha-TP9 alpha-AF7 alpha-AF8 alpha-TP10  beta-TP9  beta-AF7  \\\n",
       "0   0.657038 -0.467993  0.814466  0.643818   0.098162 -1.078152  0.973413   \n",
       "1   0.175984 -0.906638  0.832131 -0.332070   0.329700 -1.247669 -0.714387   \n",
       "2  -0.558739 -1.301238 -0.218394 -0.055393   0.249293 -1.385920  0.074558   \n",
       "3  -0.532355 -1.779209 -1.227202  0.353502  -0.087381 -0.508575 -0.075375   \n",
       "4  -0.344241 -1.137883 -1.686370  0.923469  -0.147632  0.351424 -1.111880   \n",
       "\n",
       "   beta-AF8 beta-TP10 Label  \n",
       "0 -0.246633 -0.845306   0.0  \n",
       "1 -1.326559 -1.020843   0.0  \n",
       "2 -1.289886 -0.749937   0.0  \n",
       "3 -0.891891 -0.433480   0.0  \n",
       "4 -1.395548 -0.580706   0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_raw = pd.read_pickle('tmp/music_neutral_EEG.pkl')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>delta-TP9</th>\n",
       "      <td>0.621599</td>\n",
       "      <td>0.142506</td>\n",
       "      <td>0.368229</td>\n",
       "      <td>-0.226262</td>\n",
       "      <td>-0.730689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta-AF7</th>\n",
       "      <td>0.128548</td>\n",
       "      <td>-0.297806</td>\n",
       "      <td>0.100094</td>\n",
       "      <td>-0.500569</td>\n",
       "      <td>-0.450749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta-AF8</th>\n",
       "      <td>0.041879</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>-0.451423</td>\n",
       "      <td>-0.775275</td>\n",
       "      <td>-1.475323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta-TP10</th>\n",
       "      <td>0.235494</td>\n",
       "      <td>0.203106</td>\n",
       "      <td>0.119399</td>\n",
       "      <td>-0.361730</td>\n",
       "      <td>-0.406076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta-TP9</th>\n",
       "      <td>-0.174439</td>\n",
       "      <td>0.321248</td>\n",
       "      <td>0.713166</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>-0.070954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta-AF7</th>\n",
       "      <td>0.663040</td>\n",
       "      <td>0.284305</td>\n",
       "      <td>-0.124793</td>\n",
       "      <td>0.162621</td>\n",
       "      <td>-0.605523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta-AF8</th>\n",
       "      <td>-0.854652</td>\n",
       "      <td>-0.870200</td>\n",
       "      <td>-0.141202</td>\n",
       "      <td>-0.664219</td>\n",
       "      <td>-1.163639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta-TP10</th>\n",
       "      <td>-0.458620</td>\n",
       "      <td>-0.023509</td>\n",
       "      <td>0.422463</td>\n",
       "      <td>-0.001546</td>\n",
       "      <td>-0.891475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha-TP9</th>\n",
       "      <td>-0.026204</td>\n",
       "      <td>-0.779671</td>\n",
       "      <td>-1.221266</td>\n",
       "      <td>-0.566167</td>\n",
       "      <td>0.143619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha-AF7</th>\n",
       "      <td>1.155755</td>\n",
       "      <td>0.256113</td>\n",
       "      <td>-0.518500</td>\n",
       "      <td>0.231011</td>\n",
       "      <td>-0.258749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha-AF8</th>\n",
       "      <td>0.849255</td>\n",
       "      <td>-0.142984</td>\n",
       "      <td>-1.331652</td>\n",
       "      <td>-1.071825</td>\n",
       "      <td>0.137435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha-TP10</th>\n",
       "      <td>0.313060</td>\n",
       "      <td>-0.125783</td>\n",
       "      <td>-0.536614</td>\n",
       "      <td>-1.086434</td>\n",
       "      <td>-0.855798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta-TP9</th>\n",
       "      <td>0.834757</td>\n",
       "      <td>0.613579</td>\n",
       "      <td>-0.127441</td>\n",
       "      <td>0.167880</td>\n",
       "      <td>1.017545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta-AF7</th>\n",
       "      <td>-0.037087</td>\n",
       "      <td>-0.664531</td>\n",
       "      <td>-1.004657</td>\n",
       "      <td>-0.505737</td>\n",
       "      <td>0.523758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta-AF8</th>\n",
       "      <td>0.670067</td>\n",
       "      <td>-0.361316</td>\n",
       "      <td>-0.881143</td>\n",
       "      <td>-1.246956</td>\n",
       "      <td>-0.736648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta-TP10</th>\n",
       "      <td>1.265826</td>\n",
       "      <td>0.632411</td>\n",
       "      <td>0.579444</td>\n",
       "      <td>-0.019074</td>\n",
       "      <td>-0.058714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 287       288       289       290       291\n",
       "delta-TP9   0.621599  0.142506  0.368229 -0.226262 -0.730689\n",
       "delta-AF7   0.128548 -0.297806  0.100094 -0.500569 -0.450749\n",
       "delta-AF8   0.041879  0.005136 -0.451423 -0.775275 -1.475323\n",
       "delta-TP10  0.235494  0.203106  0.119399 -0.361730 -0.406076\n",
       "theta-TP9  -0.174439  0.321248  0.713166  0.332600 -0.070954\n",
       "theta-AF7   0.663040  0.284305 -0.124793  0.162621 -0.605523\n",
       "theta-AF8  -0.854652 -0.870200 -0.141202 -0.664219 -1.163639\n",
       "theta-TP10 -0.458620 -0.023509  0.422463 -0.001546 -0.891475\n",
       "alpha-TP9  -0.026204 -0.779671 -1.221266 -0.566167  0.143619\n",
       "alpha-AF7   1.155755  0.256113 -0.518500  0.231011 -0.258749\n",
       "alpha-AF8   0.849255 -0.142984 -1.331652 -1.071825  0.137435\n",
       "alpha-TP10  0.313060 -0.125783 -0.536614 -1.086434 -0.855798\n",
       "beta-TP9    0.834757  0.613579 -0.127441  0.167880  1.017545\n",
       "beta-AF7   -0.037087 -0.664531 -1.004657 -0.505737  0.523758\n",
       "beta-AF8    0.670067 -0.361316 -0.881143 -1.246956 -0.736648\n",
       "beta-TP10   1.265826  0.632411  0.579444 -0.019074 -0.058714\n",
       "Label       1.000000  1.000000  1.000000  1.000000  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all(df_raw.tail().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>delta-TP9</th>\n",
       "      <td>292.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-1.539777</td>\n",
       "      <td>-0.580244</td>\n",
       "      <td>-0.242632</td>\n",
       "      <td>0.146494</td>\n",
       "      <td>3.501639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta-AF7</th>\n",
       "      <td>292.0</td>\n",
       "      <td>2.433366e-17</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-2.006218</td>\n",
       "      <td>-0.632384</td>\n",
       "      <td>-0.178945</td>\n",
       "      <td>0.454799</td>\n",
       "      <td>3.789085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta-AF8</th>\n",
       "      <td>292.0</td>\n",
       "      <td>6.083414e-17</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-2.214752</td>\n",
       "      <td>-0.639939</td>\n",
       "      <td>-0.085692</td>\n",
       "      <td>0.468411</td>\n",
       "      <td>3.578301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta-TP10</th>\n",
       "      <td>292.0</td>\n",
       "      <td>-4.866731e-17</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-1.872250</td>\n",
       "      <td>-0.543783</td>\n",
       "      <td>-0.245096</td>\n",
       "      <td>0.166911</td>\n",
       "      <td>3.441628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta-TP9</th>\n",
       "      <td>292.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-1.816295</td>\n",
       "      <td>-0.613013</td>\n",
       "      <td>-0.159334</td>\n",
       "      <td>0.326099</td>\n",
       "      <td>4.156030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta-AF7</th>\n",
       "      <td>292.0</td>\n",
       "      <td>4.015053e-16</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-2.559619</td>\n",
       "      <td>-0.614453</td>\n",
       "      <td>-0.128570</td>\n",
       "      <td>0.450640</td>\n",
       "      <td>4.458840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta-AF8</th>\n",
       "      <td>292.0</td>\n",
       "      <td>4.866731e-17</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-2.920800</td>\n",
       "      <td>-0.580978</td>\n",
       "      <td>-0.067485</td>\n",
       "      <td>0.419334</td>\n",
       "      <td>3.933540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta-TP10</th>\n",
       "      <td>292.0</td>\n",
       "      <td>1.946692e-16</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-1.945200</td>\n",
       "      <td>-0.652640</td>\n",
       "      <td>-0.157991</td>\n",
       "      <td>0.349644</td>\n",
       "      <td>4.163253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha-TP9</th>\n",
       "      <td>292.0</td>\n",
       "      <td>1.460019e-16</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-2.446710</td>\n",
       "      <td>-0.622812</td>\n",
       "      <td>-0.016142</td>\n",
       "      <td>0.508253</td>\n",
       "      <td>3.577243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha-AF7</th>\n",
       "      <td>292.0</td>\n",
       "      <td>-6.448419e-16</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-2.807787</td>\n",
       "      <td>-0.688082</td>\n",
       "      <td>-0.037436</td>\n",
       "      <td>0.712176</td>\n",
       "      <td>2.688622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha-AF8</th>\n",
       "      <td>292.0</td>\n",
       "      <td>-2.190029e-16</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-3.703713</td>\n",
       "      <td>-0.605180</td>\n",
       "      <td>0.024148</td>\n",
       "      <td>0.709147</td>\n",
       "      <td>2.587787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha-TP10</th>\n",
       "      <td>292.0</td>\n",
       "      <td>2.433366e-16</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-2.378870</td>\n",
       "      <td>-0.628940</td>\n",
       "      <td>-0.030610</td>\n",
       "      <td>0.425545</td>\n",
       "      <td>4.002257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta-TP9</th>\n",
       "      <td>292.0</td>\n",
       "      <td>1.387018e-15</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-1.791037</td>\n",
       "      <td>-0.665118</td>\n",
       "      <td>-0.115209</td>\n",
       "      <td>0.462909</td>\n",
       "      <td>4.037247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta-AF7</th>\n",
       "      <td>292.0</td>\n",
       "      <td>3.315461e-15</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-3.079753</td>\n",
       "      <td>-0.633422</td>\n",
       "      <td>0.032112</td>\n",
       "      <td>0.756653</td>\n",
       "      <td>2.347369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta-AF8</th>\n",
       "      <td>292.0</td>\n",
       "      <td>4.380058e-16</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-3.526155</td>\n",
       "      <td>-0.482803</td>\n",
       "      <td>0.044107</td>\n",
       "      <td>0.610654</td>\n",
       "      <td>3.488643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta-TP10</th>\n",
       "      <td>292.0</td>\n",
       "      <td>2.068361e-15</td>\n",
       "      <td>1.001717</td>\n",
       "      <td>-2.096919</td>\n",
       "      <td>-0.665483</td>\n",
       "      <td>-0.168018</td>\n",
       "      <td>0.496524</td>\n",
       "      <td>4.372645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <td>292.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count          mean       std       min       25%       50%  \\\n",
       "delta-TP9   292.0  0.000000e+00  1.001717 -1.539777 -0.580244 -0.242632   \n",
       "delta-AF7   292.0  2.433366e-17  1.001717 -2.006218 -0.632384 -0.178945   \n",
       "delta-AF8   292.0  6.083414e-17  1.001717 -2.214752 -0.639939 -0.085692   \n",
       "delta-TP10  292.0 -4.866731e-17  1.001717 -1.872250 -0.543783 -0.245096   \n",
       "theta-TP9   292.0  0.000000e+00  1.001717 -1.816295 -0.613013 -0.159334   \n",
       "theta-AF7   292.0  4.015053e-16  1.001717 -2.559619 -0.614453 -0.128570   \n",
       "theta-AF8   292.0  4.866731e-17  1.001717 -2.920800 -0.580978 -0.067485   \n",
       "theta-TP10  292.0  1.946692e-16  1.001717 -1.945200 -0.652640 -0.157991   \n",
       "alpha-TP9   292.0  1.460019e-16  1.001717 -2.446710 -0.622812 -0.016142   \n",
       "alpha-AF7   292.0 -6.448419e-16  1.001717 -2.807787 -0.688082 -0.037436   \n",
       "alpha-AF8   292.0 -2.190029e-16  1.001717 -3.703713 -0.605180  0.024148   \n",
       "alpha-TP10  292.0  2.433366e-16  1.001717 -2.378870 -0.628940 -0.030610   \n",
       "beta-TP9    292.0  1.387018e-15  1.001717 -1.791037 -0.665118 -0.115209   \n",
       "beta-AF7    292.0  3.315461e-15  1.001717 -3.079753 -0.633422  0.032112   \n",
       "beta-AF8    292.0  4.380058e-16  1.001717 -3.526155 -0.482803  0.044107   \n",
       "beta-TP10   292.0  2.068361e-15  1.001717 -2.096919 -0.665483 -0.168018   \n",
       "Label       292.0  5.000000e-01  0.500858  0.000000  0.000000  0.500000   \n",
       "\n",
       "                 75%       max  \n",
       "delta-TP9   0.146494  3.501639  \n",
       "delta-AF7   0.454799  3.789085  \n",
       "delta-AF8   0.468411  3.578301  \n",
       "delta-TP10  0.166911  3.441628  \n",
       "theta-TP9   0.326099  4.156030  \n",
       "theta-AF7   0.450640  4.458840  \n",
       "theta-AF8   0.419334  3.933540  \n",
       "theta-TP10  0.349644  4.163253  \n",
       "alpha-TP9   0.508253  3.577243  \n",
       "alpha-AF7   0.712176  2.688622  \n",
       "alpha-AF8   0.709147  2.587787  \n",
       "alpha-TP10  0.425545  4.002257  \n",
       "beta-TP9    0.462909  4.037247  \n",
       "beta-AF7    0.756653  2.347369  \n",
       "beta-AF8    0.610654  3.488643  \n",
       "beta-TP10   0.496524  4.372645  \n",
       "Label       1.000000  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all(df_raw.describe(include='all').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>delta-TP9</th>\n",
       "      <th>delta-AF7</th>\n",
       "      <th>delta-AF8</th>\n",
       "      <th>delta-TP10</th>\n",
       "      <th>theta-TP9</th>\n",
       "      <th>theta-AF7</th>\n",
       "      <th>theta-AF8</th>\n",
       "      <th>theta-TP10</th>\n",
       "      <th>alpha-TP9</th>\n",
       "      <th>alpha-AF7</th>\n",
       "      <th>alpha-AF8</th>\n",
       "      <th>alpha-TP10</th>\n",
       "      <th>beta-TP9</th>\n",
       "      <th>beta-AF7</th>\n",
       "      <th>beta-AF8</th>\n",
       "      <th>beta-TP10</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213514</td>\n",
       "      <td>2.399008</td>\n",
       "      <td>2.407957</td>\n",
       "      <td>0.393249</td>\n",
       "      <td>0.534341</td>\n",
       "      <td>0.836858</td>\n",
       "      <td>1.424246</td>\n",
       "      <td>0.657038</td>\n",
       "      <td>-0.467993</td>\n",
       "      <td>0.814466</td>\n",
       "      <td>0.643818</td>\n",
       "      <td>0.098162</td>\n",
       "      <td>-1.078152</td>\n",
       "      <td>0.973413</td>\n",
       "      <td>-0.246633</td>\n",
       "      <td>-0.845306</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.274502</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>1.514658</td>\n",
       "      <td>0.496492</td>\n",
       "      <td>0.181557</td>\n",
       "      <td>-0.012250</td>\n",
       "      <td>0.626624</td>\n",
       "      <td>0.175984</td>\n",
       "      <td>-0.906638</td>\n",
       "      <td>0.832131</td>\n",
       "      <td>-0.332070</td>\n",
       "      <td>0.329700</td>\n",
       "      <td>-1.247669</td>\n",
       "      <td>-0.714387</td>\n",
       "      <td>-1.326559</td>\n",
       "      <td>-1.020843</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069119</td>\n",
       "      <td>0.729497</td>\n",
       "      <td>1.285416</td>\n",
       "      <td>0.097301</td>\n",
       "      <td>-0.467740</td>\n",
       "      <td>0.760934</td>\n",
       "      <td>-0.579900</td>\n",
       "      <td>-0.558739</td>\n",
       "      <td>-1.301238</td>\n",
       "      <td>-0.218394</td>\n",
       "      <td>-0.055393</td>\n",
       "      <td>0.249293</td>\n",
       "      <td>-1.385920</td>\n",
       "      <td>0.074558</td>\n",
       "      <td>-1.289886</td>\n",
       "      <td>-0.749937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.480663</td>\n",
       "      <td>1.615700</td>\n",
       "      <td>-0.158431</td>\n",
       "      <td>-1.007132</td>\n",
       "      <td>1.443319</td>\n",
       "      <td>-0.212008</td>\n",
       "      <td>-0.532355</td>\n",
       "      <td>-1.779209</td>\n",
       "      <td>-1.227202</td>\n",
       "      <td>0.353502</td>\n",
       "      <td>-0.087381</td>\n",
       "      <td>-0.508575</td>\n",
       "      <td>-0.075375</td>\n",
       "      <td>-0.891891</td>\n",
       "      <td>-0.433480</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.210349</td>\n",
       "      <td>0.119917</td>\n",
       "      <td>1.832329</td>\n",
       "      <td>-0.231751</td>\n",
       "      <td>-0.616393</td>\n",
       "      <td>1.045143</td>\n",
       "      <td>-0.127250</td>\n",
       "      <td>-0.344241</td>\n",
       "      <td>-1.137883</td>\n",
       "      <td>-1.686370</td>\n",
       "      <td>0.923469</td>\n",
       "      <td>-0.147632</td>\n",
       "      <td>0.351424</td>\n",
       "      <td>-1.111880</td>\n",
       "      <td>-1.395548</td>\n",
       "      <td>-0.580706</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  delta-TP9 delta-AF7 delta-AF8 delta-TP10 theta-TP9 theta-AF7 theta-AF8  \\\n",
       "0  0.213514  2.399008  2.407957   0.393249  0.534341  0.836858  1.424246   \n",
       "1  0.274502  0.921714  1.514658   0.496492  0.181557 -0.012250  0.626624   \n",
       "2  0.069119  0.729497  1.285416   0.097301 -0.467740  0.760934 -0.579900   \n",
       "3  0.003141  0.480663  1.615700  -0.158431 -1.007132  1.443319 -0.212008   \n",
       "4 -0.210349  0.119917  1.832329  -0.231751 -0.616393  1.045143 -0.127250   \n",
       "\n",
       "  theta-TP10 alpha-TP9 alpha-AF7 alpha-AF8 alpha-TP10  beta-TP9  beta-AF7  \\\n",
       "0   0.657038 -0.467993  0.814466  0.643818   0.098162 -1.078152  0.973413   \n",
       "1   0.175984 -0.906638  0.832131 -0.332070   0.329700 -1.247669 -0.714387   \n",
       "2  -0.558739 -1.301238 -0.218394 -0.055393   0.249293 -1.385920  0.074558   \n",
       "3  -0.532355 -1.779209 -1.227202  0.353502  -0.087381 -0.508575 -0.075375   \n",
       "4  -0.344241 -1.137883 -1.686370  0.923469  -0.147632  0.351424 -1.111880   \n",
       "\n",
       "   beta-AF8 beta-TP10 Label  \n",
       "0 -0.246633 -0.845306   0.0  \n",
       "1 -1.326559 -1.020843   0.0  \n",
       "2 -1.289886 -0.749937   0.0  \n",
       "3 -0.891891 -0.433480   0.0  \n",
       "4 -1.395548 -0.580706   0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_raw.iloc[:, 0:16]\n",
    "y=df_raw.iloc[:,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tdgri\\.julia\\conda\\3\\envs\\fastai\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8943835616438355"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "m.fit(df, y)\n",
    "m.score(df,y)\n",
    "#Overtrained, but proving the model is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "        train_test_split(X, y, test_size=.1, random_state=42)\n",
    "X_train=pd.DataFrame(X_train)\n",
    "X_valid=pd.DataFrame(X_valid)\n",
    "y_train=pd.DataFrame(y_train)\n",
    "y_valid=pd.DataFrame(y_valid)\n",
    "y_train=np.ravel(y_train.reset_index(drop='True'))\n",
    "y_valid=np.ravel(y_valid.reset_index(drop='True'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3658268613176469, 0.44596878319376526, 0.4646516345146482, 0.20089580345984448]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=1, max_depth=3, bootstrap=False, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tdgri\\.julia\\conda\\3\\envs\\fastai\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 110 ms\n",
      "[0.1869808334056427, 0.34302575219167825, 0.8601445221445221, 0.5272321428571428]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "%time m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.5477225575051661, 1.0, -0.20535714285714282]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=1, bootstrap=False, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.]), 0.0, 0.0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.stack([t.predict(X_valid) for t in m.estimators_])\n",
    "preds[:,0], np.mean(preds[:,0]), y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([metrics.r2_score(y_valid, np.mean(preds[:i+1], axis=0)) for i in range(10)]);\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nearest Neighbors</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gaussian Process</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Method     Score\n",
       "0  Nearest Neighbors  0.833333\n",
       "1         Linear SVM  0.733333\n",
       "2            RBF SVM  0.466667\n",
       "3   Gaussian Process  0.833333\n",
       "4      Decision Tree  0.733333\n",
       "5      Random Forest  0.800000\n",
       "6         Neural Net  0.933333\n",
       "7           AdaBoost  0.766667\n",
       "8        Naive Bayes  0.700000\n",
       "9                QDA  0.800000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                    np.arange(y_min, y_max, h))\n",
    "\n",
    "score_save = []\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_valid, y_valid)\n",
    "    score_save.append(score)\n",
    "dummy_data1 = {\n",
    "        'Method': names,\n",
    "        'Score': score_save}\n",
    "results_data = pd.DataFrame(dummy_data1, columns = ['Method', 'Score'])\n",
    "\n",
    "results_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21794608967740306, 0.3496841623141627, 0.8099869356001601, 0.5087003926963306, 0.36881029121369524]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>delta-TP9</th>\n",
       "      <th>delta-AF7</th>\n",
       "      <th>delta-AF8</th>\n",
       "      <th>delta-TP10</th>\n",
       "      <th>theta-TP9</th>\n",
       "      <th>theta-AF7</th>\n",
       "      <th>theta-AF8</th>\n",
       "      <th>theta-TP10</th>\n",
       "      <th>alpha-TP9</th>\n",
       "      <th>alpha-AF7</th>\n",
       "      <th>alpha-AF8</th>\n",
       "      <th>alpha-TP10</th>\n",
       "      <th>beta-TP9</th>\n",
       "      <th>beta-AF7</th>\n",
       "      <th>beta-AF8</th>\n",
       "      <th>beta-TP10</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213514</td>\n",
       "      <td>2.399008</td>\n",
       "      <td>2.407957</td>\n",
       "      <td>0.393249</td>\n",
       "      <td>0.534341</td>\n",
       "      <td>0.836858</td>\n",
       "      <td>1.424246</td>\n",
       "      <td>0.657038</td>\n",
       "      <td>-0.467993</td>\n",
       "      <td>0.814466</td>\n",
       "      <td>0.643818</td>\n",
       "      <td>0.098162</td>\n",
       "      <td>-1.078152</td>\n",
       "      <td>0.973413</td>\n",
       "      <td>-0.246633</td>\n",
       "      <td>-0.845306</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.274502</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>1.514658</td>\n",
       "      <td>0.496492</td>\n",
       "      <td>0.181557</td>\n",
       "      <td>-0.012250</td>\n",
       "      <td>0.626624</td>\n",
       "      <td>0.175984</td>\n",
       "      <td>-0.906638</td>\n",
       "      <td>0.832131</td>\n",
       "      <td>-0.332070</td>\n",
       "      <td>0.329700</td>\n",
       "      <td>-1.247669</td>\n",
       "      <td>-0.714387</td>\n",
       "      <td>-1.326559</td>\n",
       "      <td>-1.020843</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069119</td>\n",
       "      <td>0.729497</td>\n",
       "      <td>1.285416</td>\n",
       "      <td>0.097301</td>\n",
       "      <td>-0.467740</td>\n",
       "      <td>0.760934</td>\n",
       "      <td>-0.579900</td>\n",
       "      <td>-0.558739</td>\n",
       "      <td>-1.301238</td>\n",
       "      <td>-0.218394</td>\n",
       "      <td>-0.055393</td>\n",
       "      <td>0.249293</td>\n",
       "      <td>-1.385920</td>\n",
       "      <td>0.074558</td>\n",
       "      <td>-1.289886</td>\n",
       "      <td>-0.749937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.480663</td>\n",
       "      <td>1.615700</td>\n",
       "      <td>-0.158431</td>\n",
       "      <td>-1.007132</td>\n",
       "      <td>1.443319</td>\n",
       "      <td>-0.212008</td>\n",
       "      <td>-0.532355</td>\n",
       "      <td>-1.779209</td>\n",
       "      <td>-1.227202</td>\n",
       "      <td>0.353502</td>\n",
       "      <td>-0.087381</td>\n",
       "      <td>-0.508575</td>\n",
       "      <td>-0.075375</td>\n",
       "      <td>-0.891891</td>\n",
       "      <td>-0.433480</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.210349</td>\n",
       "      <td>0.119917</td>\n",
       "      <td>1.832329</td>\n",
       "      <td>-0.231751</td>\n",
       "      <td>-0.616393</td>\n",
       "      <td>1.045143</td>\n",
       "      <td>-0.127250</td>\n",
       "      <td>-0.344241</td>\n",
       "      <td>-1.137883</td>\n",
       "      <td>-1.686370</td>\n",
       "      <td>0.923469</td>\n",
       "      <td>-0.147632</td>\n",
       "      <td>0.351424</td>\n",
       "      <td>-1.111880</td>\n",
       "      <td>-1.395548</td>\n",
       "      <td>-0.580706</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.051825</td>\n",
       "      <td>-0.263452</td>\n",
       "      <td>1.119956</td>\n",
       "      <td>-0.327761</td>\n",
       "      <td>-0.505222</td>\n",
       "      <td>0.152652</td>\n",
       "      <td>-0.513246</td>\n",
       "      <td>-0.258107</td>\n",
       "      <td>-0.828238</td>\n",
       "      <td>-1.597773</td>\n",
       "      <td>0.385438</td>\n",
       "      <td>-0.313688</td>\n",
       "      <td>0.287174</td>\n",
       "      <td>-1.351710</td>\n",
       "      <td>-2.052439</td>\n",
       "      <td>-0.951017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.086974</td>\n",
       "      <td>-0.671780</td>\n",
       "      <td>1.001618</td>\n",
       "      <td>-0.122757</td>\n",
       "      <td>-0.682590</td>\n",
       "      <td>0.430467</td>\n",
       "      <td>-1.075897</td>\n",
       "      <td>-0.075021</td>\n",
       "      <td>-0.448091</td>\n",
       "      <td>-0.746614</td>\n",
       "      <td>-0.298868</td>\n",
       "      <td>-0.503815</td>\n",
       "      <td>-0.541788</td>\n",
       "      <td>-0.272356</td>\n",
       "      <td>-1.350803</td>\n",
       "      <td>-1.294469</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.480012</td>\n",
       "      <td>-2.006218</td>\n",
       "      <td>-0.028464</td>\n",
       "      <td>-0.295416</td>\n",
       "      <td>-0.538043</td>\n",
       "      <td>-0.236132</td>\n",
       "      <td>-1.324888</td>\n",
       "      <td>-0.092515</td>\n",
       "      <td>-0.013630</td>\n",
       "      <td>0.435665</td>\n",
       "      <td>-0.533208</td>\n",
       "      <td>0.143743</td>\n",
       "      <td>-1.518596</td>\n",
       "      <td>0.596153</td>\n",
       "      <td>-0.822614</td>\n",
       "      <td>-0.923277</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.405463</td>\n",
       "      <td>-1.644300</td>\n",
       "      <td>-0.270670</td>\n",
       "      <td>-0.242053</td>\n",
       "      <td>-0.017734</td>\n",
       "      <td>-0.174221</td>\n",
       "      <td>-0.019164</td>\n",
       "      <td>0.089024</td>\n",
       "      <td>0.491391</td>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.077964</td>\n",
       "      <td>0.502514</td>\n",
       "      <td>-1.016791</td>\n",
       "      <td>0.695858</td>\n",
       "      <td>-1.372176</td>\n",
       "      <td>-0.801689</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.432286</td>\n",
       "      <td>-0.152718</td>\n",
       "      <td>0.598483</td>\n",
       "      <td>-0.115877</td>\n",
       "      <td>0.133831</td>\n",
       "      <td>0.401195</td>\n",
       "      <td>0.130803</td>\n",
       "      <td>0.122528</td>\n",
       "      <td>0.354565</td>\n",
       "      <td>0.811382</td>\n",
       "      <td>0.698648</td>\n",
       "      <td>-0.230683</td>\n",
       "      <td>-0.320636</td>\n",
       "      <td>0.151858</td>\n",
       "      <td>-1.347009</td>\n",
       "      <td>-1.015522</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.146932</td>\n",
       "      <td>0.235146</td>\n",
       "      <td>0.294602</td>\n",
       "      <td>-0.572148</td>\n",
       "      <td>0.227806</td>\n",
       "      <td>0.450138</td>\n",
       "      <td>-0.279869</td>\n",
       "      <td>-0.306065</td>\n",
       "      <td>-0.867224</td>\n",
       "      <td>1.252146</td>\n",
       "      <td>0.535048</td>\n",
       "      <td>-0.178032</td>\n",
       "      <td>0.251012</td>\n",
       "      <td>-0.823283</td>\n",
       "      <td>-1.439193</td>\n",
       "      <td>-0.262769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.001430</td>\n",
       "      <td>0.866532</td>\n",
       "      <td>0.744292</td>\n",
       "      <td>-0.797730</td>\n",
       "      <td>0.307789</td>\n",
       "      <td>0.860581</td>\n",
       "      <td>0.251318</td>\n",
       "      <td>-0.248140</td>\n",
       "      <td>-0.017924</td>\n",
       "      <td>0.818161</td>\n",
       "      <td>0.089419</td>\n",
       "      <td>1.150737</td>\n",
       "      <td>0.138925</td>\n",
       "      <td>-1.311787</td>\n",
       "      <td>-2.067773</td>\n",
       "      <td>0.070253</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.146348</td>\n",
       "      <td>0.618151</td>\n",
       "      <td>0.610340</td>\n",
       "      <td>-1.154899</td>\n",
       "      <td>0.408110</td>\n",
       "      <td>1.329480</td>\n",
       "      <td>-0.001540</td>\n",
       "      <td>-0.439488</td>\n",
       "      <td>-0.033736</td>\n",
       "      <td>0.732197</td>\n",
       "      <td>-0.102318</td>\n",
       "      <td>1.281039</td>\n",
       "      <td>-0.735398</td>\n",
       "      <td>-1.222797</td>\n",
       "      <td>-1.239380</td>\n",
       "      <td>0.090161</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.103998</td>\n",
       "      <td>0.263626</td>\n",
       "      <td>0.236944</td>\n",
       "      <td>-1.133041</td>\n",
       "      <td>-0.145694</td>\n",
       "      <td>1.157310</td>\n",
       "      <td>-0.794460</td>\n",
       "      <td>-0.143984</td>\n",
       "      <td>-0.082622</td>\n",
       "      <td>0.288880</td>\n",
       "      <td>-1.421855</td>\n",
       "      <td>0.213885</td>\n",
       "      <td>-0.590549</td>\n",
       "      <td>-0.155423</td>\n",
       "      <td>-0.409051</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.067884</td>\n",
       "      <td>0.280909</td>\n",
       "      <td>-0.006766</td>\n",
       "      <td>-0.396238</td>\n",
       "      <td>-0.612612</td>\n",
       "      <td>1.093421</td>\n",
       "      <td>-0.599752</td>\n",
       "      <td>-0.686979</td>\n",
       "      <td>0.392291</td>\n",
       "      <td>0.917120</td>\n",
       "      <td>-1.160279</td>\n",
       "      <td>0.423007</td>\n",
       "      <td>0.201738</td>\n",
       "      <td>1.077944</td>\n",
       "      <td>-1.138245</td>\n",
       "      <td>-0.058830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.108029</td>\n",
       "      <td>0.704948</td>\n",
       "      <td>-0.516454</td>\n",
       "      <td>-0.054405</td>\n",
       "      <td>-0.911179</td>\n",
       "      <td>1.046748</td>\n",
       "      <td>-0.381751</td>\n",
       "      <td>-1.299481</td>\n",
       "      <td>0.029613</td>\n",
       "      <td>2.266867</td>\n",
       "      <td>0.265729</td>\n",
       "      <td>0.369297</td>\n",
       "      <td>-0.149129</td>\n",
       "      <td>1.494485</td>\n",
       "      <td>-0.851704</td>\n",
       "      <td>-0.349241</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.128855</td>\n",
       "      <td>1.362195</td>\n",
       "      <td>-0.057506</td>\n",
       "      <td>-0.074408</td>\n",
       "      <td>-0.622653</td>\n",
       "      <td>0.050969</td>\n",
       "      <td>-0.896629</td>\n",
       "      <td>-1.056867</td>\n",
       "      <td>-1.398627</td>\n",
       "      <td>1.957782</td>\n",
       "      <td>0.166856</td>\n",
       "      <td>0.286042</td>\n",
       "      <td>-1.065816</td>\n",
       "      <td>1.250892</td>\n",
       "      <td>-1.077530</td>\n",
       "      <td>-0.409245</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.128464</td>\n",
       "      <td>0.859343</td>\n",
       "      <td>-0.277063</td>\n",
       "      <td>-0.139770</td>\n",
       "      <td>-0.014030</td>\n",
       "      <td>-1.118520</td>\n",
       "      <td>-1.396692</td>\n",
       "      <td>-0.653213</td>\n",
       "      <td>-1.812951</td>\n",
       "      <td>-0.149790</td>\n",
       "      <td>-1.393145</td>\n",
       "      <td>-0.022676</td>\n",
       "      <td>-0.881834</td>\n",
       "      <td>1.114260</td>\n",
       "      <td>-3.526155</td>\n",
       "      <td>-1.025142</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.229944</td>\n",
       "      <td>0.571342</td>\n",
       "      <td>-1.075829</td>\n",
       "      <td>-0.474831</td>\n",
       "      <td>-0.224679</td>\n",
       "      <td>-0.372622</td>\n",
       "      <td>-0.752135</td>\n",
       "      <td>-0.190520</td>\n",
       "      <td>-0.215686</td>\n",
       "      <td>-1.686898</td>\n",
       "      <td>-1.489736</td>\n",
       "      <td>-0.632539</td>\n",
       "      <td>-1.158338</td>\n",
       "      <td>2.159359</td>\n",
       "      <td>-2.899488</td>\n",
       "      <td>-0.871926</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.220150</td>\n",
       "      <td>-1.361181</td>\n",
       "      <td>-1.257925</td>\n",
       "      <td>-0.341096</td>\n",
       "      <td>-0.829263</td>\n",
       "      <td>-0.094745</td>\n",
       "      <td>-0.332439</td>\n",
       "      <td>-0.151970</td>\n",
       "      <td>0.291878</td>\n",
       "      <td>-0.286571</td>\n",
       "      <td>0.022930</td>\n",
       "      <td>0.051437</td>\n",
       "      <td>-1.255987</td>\n",
       "      <td>0.972860</td>\n",
       "      <td>-1.483333</td>\n",
       "      <td>-0.529287</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.075262</td>\n",
       "      <td>-1.554477</td>\n",
       "      <td>-1.113769</td>\n",
       "      <td>-0.527430</td>\n",
       "      <td>-0.603400</td>\n",
       "      <td>-0.548110</td>\n",
       "      <td>-0.618227</td>\n",
       "      <td>-0.367569</td>\n",
       "      <td>-0.581791</td>\n",
       "      <td>0.071743</td>\n",
       "      <td>0.909140</td>\n",
       "      <td>0.359319</td>\n",
       "      <td>-0.197760</td>\n",
       "      <td>-1.543971</td>\n",
       "      <td>-2.134971</td>\n",
       "      <td>-0.322525</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.106924</td>\n",
       "      <td>-0.965343</td>\n",
       "      <td>0.072309</td>\n",
       "      <td>-0.694574</td>\n",
       "      <td>-0.562903</td>\n",
       "      <td>-0.930546</td>\n",
       "      <td>0.135469</td>\n",
       "      <td>-0.955379</td>\n",
       "      <td>-0.008098</td>\n",
       "      <td>0.496828</td>\n",
       "      <td>1.026037</td>\n",
       "      <td>1.101956</td>\n",
       "      <td>-0.671572</td>\n",
       "      <td>-1.541274</td>\n",
       "      <td>-3.062097</td>\n",
       "      <td>-0.833115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.172397</td>\n",
       "      <td>-0.708051</td>\n",
       "      <td>0.153175</td>\n",
       "      <td>-0.907947</td>\n",
       "      <td>-0.338745</td>\n",
       "      <td>-0.474828</td>\n",
       "      <td>0.361558</td>\n",
       "      <td>-0.940465</td>\n",
       "      <td>0.079976</td>\n",
       "      <td>0.722999</td>\n",
       "      <td>0.025365</td>\n",
       "      <td>0.743568</td>\n",
       "      <td>-1.218136</td>\n",
       "      <td>-1.856360</td>\n",
       "      <td>-2.510667</td>\n",
       "      <td>-1.003153</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.150760</td>\n",
       "      <td>0.466819</td>\n",
       "      <td>1.005948</td>\n",
       "      <td>-0.083369</td>\n",
       "      <td>-0.541209</td>\n",
       "      <td>-0.134129</td>\n",
       "      <td>-0.035947</td>\n",
       "      <td>-0.738934</td>\n",
       "      <td>-1.288300</td>\n",
       "      <td>0.929868</td>\n",
       "      <td>-0.454915</td>\n",
       "      <td>-0.920439</td>\n",
       "      <td>-0.581734</td>\n",
       "      <td>-0.100377</td>\n",
       "      <td>-1.511623</td>\n",
       "      <td>-0.889891</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.579743</td>\n",
       "      <td>0.633773</td>\n",
       "      <td>1.026589</td>\n",
       "      <td>-0.183963</td>\n",
       "      <td>-0.686479</td>\n",
       "      <td>0.085274</td>\n",
       "      <td>-0.472252</td>\n",
       "      <td>-0.456016</td>\n",
       "      <td>-2.446710</td>\n",
       "      <td>0.798586</td>\n",
       "      <td>-0.958334</td>\n",
       "      <td>-1.870411</td>\n",
       "      <td>0.279462</td>\n",
       "      <td>0.605390</td>\n",
       "      <td>-0.612778</td>\n",
       "      <td>-0.072402</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.625463</td>\n",
       "      <td>0.653343</td>\n",
       "      <td>0.373161</td>\n",
       "      <td>-0.315085</td>\n",
       "      <td>-0.848928</td>\n",
       "      <td>0.607960</td>\n",
       "      <td>-0.466801</td>\n",
       "      <td>-1.059609</td>\n",
       "      <td>-0.521059</td>\n",
       "      <td>0.761648</td>\n",
       "      <td>0.173717</td>\n",
       "      <td>-1.706728</td>\n",
       "      <td>0.367991</td>\n",
       "      <td>0.392148</td>\n",
       "      <td>-0.373201</td>\n",
       "      <td>0.166671</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.229980</td>\n",
       "      <td>0.352520</td>\n",
       "      <td>0.886853</td>\n",
       "      <td>-0.498656</td>\n",
       "      <td>-0.871644</td>\n",
       "      <td>0.715199</td>\n",
       "      <td>0.448787</td>\n",
       "      <td>-1.945200</td>\n",
       "      <td>0.094593</td>\n",
       "      <td>-1.020576</td>\n",
       "      <td>1.159258</td>\n",
       "      <td>-1.016866</td>\n",
       "      <td>-0.144165</td>\n",
       "      <td>0.521299</td>\n",
       "      <td>-0.527413</td>\n",
       "      <td>-0.388440</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.013421</td>\n",
       "      <td>0.177602</td>\n",
       "      <td>0.404552</td>\n",
       "      <td>-0.067575</td>\n",
       "      <td>-0.339092</td>\n",
       "      <td>0.660191</td>\n",
       "      <td>0.277448</td>\n",
       "      <td>-0.652449</td>\n",
       "      <td>0.479082</td>\n",
       "      <td>-0.483437</td>\n",
       "      <td>1.976568</td>\n",
       "      <td>-0.396122</td>\n",
       "      <td>-0.991673</td>\n",
       "      <td>0.867033</td>\n",
       "      <td>0.318450</td>\n",
       "      <td>-0.103488</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.146794</td>\n",
       "      <td>-0.060504</td>\n",
       "      <td>1.289442</td>\n",
       "      <td>-0.208396</td>\n",
       "      <td>0.205269</td>\n",
       "      <td>0.316208</td>\n",
       "      <td>0.454721</td>\n",
       "      <td>0.051697</td>\n",
       "      <td>0.251493</td>\n",
       "      <td>1.052970</td>\n",
       "      <td>1.571304</td>\n",
       "      <td>-0.145694</td>\n",
       "      <td>-0.262660</td>\n",
       "      <td>0.340540</td>\n",
       "      <td>0.943424</td>\n",
       "      <td>-0.259735</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.154859</td>\n",
       "      <td>-0.354284</td>\n",
       "      <td>1.067686</td>\n",
       "      <td>0.158146</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>0.152232</td>\n",
       "      <td>0.288690</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>0.067617</td>\n",
       "      <td>1.011340</td>\n",
       "      <td>-0.583221</td>\n",
       "      <td>0.537474</td>\n",
       "      <td>0.758452</td>\n",
       "      <td>-0.506645</td>\n",
       "      <td>-0.312422</td>\n",
       "      <td>-0.031583</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>-0.751458</td>\n",
       "      <td>-0.610216</td>\n",
       "      <td>-0.161276</td>\n",
       "      <td>0.036396</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>-1.206478</td>\n",
       "      <td>0.162563</td>\n",
       "      <td>-0.253040</td>\n",
       "      <td>0.465269</td>\n",
       "      <td>-2.807787</td>\n",
       "      <td>0.206365</td>\n",
       "      <td>-1.635500</td>\n",
       "      <td>1.173014</td>\n",
       "      <td>-1.004578</td>\n",
       "      <td>0.387729</td>\n",
       "      <td>1.224671</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>-0.633193</td>\n",
       "      <td>-1.122481</td>\n",
       "      <td>-0.054847</td>\n",
       "      <td>-0.360719</td>\n",
       "      <td>0.378721</td>\n",
       "      <td>-0.837366</td>\n",
       "      <td>-0.600157</td>\n",
       "      <td>-0.874927</td>\n",
       "      <td>0.581135</td>\n",
       "      <td>-1.802812</td>\n",
       "      <td>-0.115994</td>\n",
       "      <td>-1.835811</td>\n",
       "      <td>1.470226</td>\n",
       "      <td>-2.189751</td>\n",
       "      <td>0.670324</td>\n",
       "      <td>0.553364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>-0.392653</td>\n",
       "      <td>-0.737491</td>\n",
       "      <td>-0.500402</td>\n",
       "      <td>-0.281268</td>\n",
       "      <td>-0.115444</td>\n",
       "      <td>-0.229041</td>\n",
       "      <td>0.434597</td>\n",
       "      <td>-0.716015</td>\n",
       "      <td>-0.514144</td>\n",
       "      <td>-0.694647</td>\n",
       "      <td>-0.963604</td>\n",
       "      <td>-1.169185</td>\n",
       "      <td>0.071527</td>\n",
       "      <td>-0.187068</td>\n",
       "      <td>1.086861</td>\n",
       "      <td>0.740411</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>-0.716079</td>\n",
       "      <td>-1.022264</td>\n",
       "      <td>-0.858400</td>\n",
       "      <td>-0.395495</td>\n",
       "      <td>0.184340</td>\n",
       "      <td>0.377695</td>\n",
       "      <td>0.415141</td>\n",
       "      <td>-0.030307</td>\n",
       "      <td>-0.092597</td>\n",
       "      <td>0.469911</td>\n",
       "      <td>-0.931781</td>\n",
       "      <td>0.173419</td>\n",
       "      <td>-1.497404</td>\n",
       "      <td>-0.161618</td>\n",
       "      <td>0.248853</td>\n",
       "      <td>0.413739</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>-1.267904</td>\n",
       "      <td>-0.641252</td>\n",
       "      <td>-1.454673</td>\n",
       "      <td>-0.321021</td>\n",
       "      <td>0.640080</td>\n",
       "      <td>0.177762</td>\n",
       "      <td>-0.083836</td>\n",
       "      <td>0.453797</td>\n",
       "      <td>0.252103</td>\n",
       "      <td>0.915598</td>\n",
       "      <td>-0.265297</td>\n",
       "      <td>0.129005</td>\n",
       "      <td>-0.427761</td>\n",
       "      <td>0.791337</td>\n",
       "      <td>-0.731442</td>\n",
       "      <td>-0.645931</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>-0.631198</td>\n",
       "      <td>-0.423214</td>\n",
       "      <td>-1.315832</td>\n",
       "      <td>-0.376819</td>\n",
       "      <td>0.288431</td>\n",
       "      <td>-0.220710</td>\n",
       "      <td>0.014223</td>\n",
       "      <td>-0.182441</td>\n",
       "      <td>0.727881</td>\n",
       "      <td>1.238689</td>\n",
       "      <td>1.192414</td>\n",
       "      <td>-0.728431</td>\n",
       "      <td>0.619864</td>\n",
       "      <td>1.545326</td>\n",
       "      <td>-1.509833</td>\n",
       "      <td>-0.544240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>-0.267619</td>\n",
       "      <td>-0.688307</td>\n",
       "      <td>-0.984739</td>\n",
       "      <td>-0.343621</td>\n",
       "      <td>-0.677592</td>\n",
       "      <td>0.419800</td>\n",
       "      <td>0.554753</td>\n",
       "      <td>-0.437086</td>\n",
       "      <td>0.915015</td>\n",
       "      <td>1.319920</td>\n",
       "      <td>1.392516</td>\n",
       "      <td>-0.732860</td>\n",
       "      <td>0.813330</td>\n",
       "      <td>1.301755</td>\n",
       "      <td>-1.520715</td>\n",
       "      <td>-0.786434</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>-0.423743</td>\n",
       "      <td>-0.571219</td>\n",
       "      <td>-0.358224</td>\n",
       "      <td>-0.210009</td>\n",
       "      <td>-0.184537</td>\n",
       "      <td>0.856991</td>\n",
       "      <td>0.393675</td>\n",
       "      <td>0.288659</td>\n",
       "      <td>0.194818</td>\n",
       "      <td>0.041240</td>\n",
       "      <td>0.929745</td>\n",
       "      <td>-1.065491</td>\n",
       "      <td>0.084643</td>\n",
       "      <td>-0.063926</td>\n",
       "      <td>-1.446977</td>\n",
       "      <td>-0.889520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-0.565201</td>\n",
       "      <td>-0.112536</td>\n",
       "      <td>0.134301</td>\n",
       "      <td>-0.384410</td>\n",
       "      <td>-0.182179</td>\n",
       "      <td>0.970412</td>\n",
       "      <td>-0.312539</td>\n",
       "      <td>0.090177</td>\n",
       "      <td>0.151709</td>\n",
       "      <td>0.319037</td>\n",
       "      <td>0.305943</td>\n",
       "      <td>-0.635190</td>\n",
       "      <td>-0.113333</td>\n",
       "      <td>0.391727</td>\n",
       "      <td>-0.715345</td>\n",
       "      <td>-0.164591</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>-0.735997</td>\n",
       "      <td>-0.008424</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>-0.733817</td>\n",
       "      <td>-0.362947</td>\n",
       "      <td>0.519772</td>\n",
       "      <td>0.063147</td>\n",
       "      <td>-0.143916</td>\n",
       "      <td>0.217183</td>\n",
       "      <td>1.340800</td>\n",
       "      <td>1.293519</td>\n",
       "      <td>-0.936617</td>\n",
       "      <td>-0.280943</td>\n",
       "      <td>1.053654</td>\n",
       "      <td>-0.230961</td>\n",
       "      <td>1.294397</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>-0.488950</td>\n",
       "      <td>0.099833</td>\n",
       "      <td>0.629765</td>\n",
       "      <td>-0.661423</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.037508</td>\n",
       "      <td>0.056930</td>\n",
       "      <td>0.214998</td>\n",
       "      <td>0.707054</td>\n",
       "      <td>1.571159</td>\n",
       "      <td>1.193769</td>\n",
       "      <td>-1.355068</td>\n",
       "      <td>0.331677</td>\n",
       "      <td>1.429783</td>\n",
       "      <td>0.148198</td>\n",
       "      <td>1.648714</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>-0.518196</td>\n",
       "      <td>-0.609915</td>\n",
       "      <td>0.476455</td>\n",
       "      <td>-1.141158</td>\n",
       "      <td>0.098360</td>\n",
       "      <td>0.229413</td>\n",
       "      <td>-0.851217</td>\n",
       "      <td>-0.230176</td>\n",
       "      <td>0.703755</td>\n",
       "      <td>1.049569</td>\n",
       "      <td>-0.488490</td>\n",
       "      <td>-0.225198</td>\n",
       "      <td>0.852984</td>\n",
       "      <td>1.503196</td>\n",
       "      <td>-0.274591</td>\n",
       "      <td>0.510139</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>-1.091459</td>\n",
       "      <td>-0.532345</td>\n",
       "      <td>0.494349</td>\n",
       "      <td>-0.352449</td>\n",
       "      <td>-0.015291</td>\n",
       "      <td>-0.566431</td>\n",
       "      <td>-0.504227</td>\n",
       "      <td>-0.401922</td>\n",
       "      <td>0.428411</td>\n",
       "      <td>-0.727007</td>\n",
       "      <td>-1.680978</td>\n",
       "      <td>0.876752</td>\n",
       "      <td>1.127848</td>\n",
       "      <td>0.672176</td>\n",
       "      <td>-0.247189</td>\n",
       "      <td>-0.062704</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>-0.830376</td>\n",
       "      <td>-0.220333</td>\n",
       "      <td>0.225104</td>\n",
       "      <td>-0.222778</td>\n",
       "      <td>0.542507</td>\n",
       "      <td>-0.173958</td>\n",
       "      <td>-1.610090</td>\n",
       "      <td>0.022923</td>\n",
       "      <td>0.441008</td>\n",
       "      <td>1.088264</td>\n",
       "      <td>-0.512342</td>\n",
       "      <td>1.155613</td>\n",
       "      <td>1.460273</td>\n",
       "      <td>0.985298</td>\n",
       "      <td>0.553466</td>\n",
       "      <td>1.659895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>-0.591421</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.161249</td>\n",
       "      <td>-0.395154</td>\n",
       "      <td>0.125585</td>\n",
       "      <td>0.527319</td>\n",
       "      <td>-1.837182</td>\n",
       "      <td>-0.506985</td>\n",
       "      <td>-0.353646</td>\n",
       "      <td>1.831691</td>\n",
       "      <td>1.260005</td>\n",
       "      <td>0.261513</td>\n",
       "      <td>1.937831</td>\n",
       "      <td>1.790504</td>\n",
       "      <td>0.664807</td>\n",
       "      <td>2.528723</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>-0.320731</td>\n",
       "      <td>-0.347213</td>\n",
       "      <td>-0.457326</td>\n",
       "      <td>-0.301098</td>\n",
       "      <td>-0.515956</td>\n",
       "      <td>0.049768</td>\n",
       "      <td>-1.414502</td>\n",
       "      <td>-0.508958</td>\n",
       "      <td>0.834722</td>\n",
       "      <td>0.700527</td>\n",
       "      <td>1.211059</td>\n",
       "      <td>0.277951</td>\n",
       "      <td>0.832158</td>\n",
       "      <td>0.909237</td>\n",
       "      <td>0.782942</td>\n",
       "      <td>1.324878</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>-0.193964</td>\n",
       "      <td>-1.317364</td>\n",
       "      <td>-1.177051</td>\n",
       "      <td>0.064863</td>\n",
       "      <td>0.942513</td>\n",
       "      <td>-0.935262</td>\n",
       "      <td>-2.685323</td>\n",
       "      <td>0.517734</td>\n",
       "      <td>1.234924</td>\n",
       "      <td>-0.060353</td>\n",
       "      <td>0.413310</td>\n",
       "      <td>0.605364</td>\n",
       "      <td>1.397067</td>\n",
       "      <td>0.396437</td>\n",
       "      <td>1.182025</td>\n",
       "      <td>0.612418</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.484398</td>\n",
       "      <td>-1.298334</td>\n",
       "      <td>-1.466594</td>\n",
       "      <td>0.728681</td>\n",
       "      <td>1.544378</td>\n",
       "      <td>-1.503549</td>\n",
       "      <td>-2.920800</td>\n",
       "      <td>1.127777</td>\n",
       "      <td>1.366370</td>\n",
       "      <td>0.266824</td>\n",
       "      <td>1.281940</td>\n",
       "      <td>1.333339</td>\n",
       "      <td>2.040250</td>\n",
       "      <td>-0.863296</td>\n",
       "      <td>1.339852</td>\n",
       "      <td>1.471146</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.331313</td>\n",
       "      <td>-0.964134</td>\n",
       "      <td>-1.258116</td>\n",
       "      <td>0.445556</td>\n",
       "      <td>1.033292</td>\n",
       "      <td>-1.011368</td>\n",
       "      <td>-2.479521</td>\n",
       "      <td>0.734708</td>\n",
       "      <td>0.748035</td>\n",
       "      <td>-0.465168</td>\n",
       "      <td>1.254991</td>\n",
       "      <td>0.606407</td>\n",
       "      <td>1.233160</td>\n",
       "      <td>-2.348730</td>\n",
       "      <td>0.315625</td>\n",
       "      <td>0.996471</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-0.334840</td>\n",
       "      <td>-0.865352</td>\n",
       "      <td>-0.432529</td>\n",
       "      <td>0.030444</td>\n",
       "      <td>0.434598</td>\n",
       "      <td>0.034882</td>\n",
       "      <td>-1.721293</td>\n",
       "      <td>0.236212</td>\n",
       "      <td>-0.269558</td>\n",
       "      <td>-0.609350</td>\n",
       "      <td>0.965859</td>\n",
       "      <td>-1.018153</td>\n",
       "      <td>-0.460573</td>\n",
       "      <td>-1.926787</td>\n",
       "      <td>0.220132</td>\n",
       "      <td>-0.251230</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>-0.818510</td>\n",
       "      <td>-0.752782</td>\n",
       "      <td>-0.511477</td>\n",
       "      <td>-0.888362</td>\n",
       "      <td>0.341487</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>-1.538431</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>-0.611236</td>\n",
       "      <td>0.465059</td>\n",
       "      <td>0.517533</td>\n",
       "      <td>-0.571996</td>\n",
       "      <td>-0.251092</td>\n",
       "      <td>-0.023257</td>\n",
       "      <td>-0.094554</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>-0.467644</td>\n",
       "      <td>-0.759969</td>\n",
       "      <td>-0.463293</td>\n",
       "      <td>-0.876372</td>\n",
       "      <td>0.032144</td>\n",
       "      <td>-0.257510</td>\n",
       "      <td>-1.388784</td>\n",
       "      <td>-0.875743</td>\n",
       "      <td>0.170356</td>\n",
       "      <td>-0.553645</td>\n",
       "      <td>-0.020402</td>\n",
       "      <td>0.858159</td>\n",
       "      <td>-0.055794</td>\n",
       "      <td>-0.179972</td>\n",
       "      <td>0.517955</td>\n",
       "      <td>0.538673</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>-0.062382</td>\n",
       "      <td>-0.473620</td>\n",
       "      <td>-0.988784</td>\n",
       "      <td>-0.413188</td>\n",
       "      <td>0.335930</td>\n",
       "      <td>-0.407431</td>\n",
       "      <td>-0.477790</td>\n",
       "      <td>-0.902575</td>\n",
       "      <td>-0.223979</td>\n",
       "      <td>0.821292</td>\n",
       "      <td>0.814628</td>\n",
       "      <td>-0.289759</td>\n",
       "      <td>-0.220196</td>\n",
       "      <td>-1.485033</td>\n",
       "      <td>1.194371</td>\n",
       "      <td>0.428822</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.304108</td>\n",
       "      <td>-0.219053</td>\n",
       "      <td>-1.497537</td>\n",
       "      <td>-0.465347</td>\n",
       "      <td>-0.070486</td>\n",
       "      <td>-0.741291</td>\n",
       "      <td>-0.004767</td>\n",
       "      <td>-1.349954</td>\n",
       "      <td>0.323032</td>\n",
       "      <td>1.647187</td>\n",
       "      <td>0.873026</td>\n",
       "      <td>-1.011018</td>\n",
       "      <td>-0.118026</td>\n",
       "      <td>-1.016163</td>\n",
       "      <td>1.827988</td>\n",
       "      <td>0.517917</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.069618</td>\n",
       "      <td>-0.669605</td>\n",
       "      <td>-0.522444</td>\n",
       "      <td>-0.012146</td>\n",
       "      <td>-0.102132</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.071879</td>\n",
       "      <td>-0.952852</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>1.286663</td>\n",
       "      <td>0.226334</td>\n",
       "      <td>-0.055925</td>\n",
       "      <td>0.369780</td>\n",
       "      <td>0.039462</td>\n",
       "      <td>1.810562</td>\n",
       "      <td>1.015129</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.621599</td>\n",
       "      <td>0.128548</td>\n",
       "      <td>0.041879</td>\n",
       "      <td>0.235494</td>\n",
       "      <td>-0.174439</td>\n",
       "      <td>0.663040</td>\n",
       "      <td>-0.854652</td>\n",
       "      <td>-0.458620</td>\n",
       "      <td>-0.026204</td>\n",
       "      <td>1.155755</td>\n",
       "      <td>0.849255</td>\n",
       "      <td>0.313060</td>\n",
       "      <td>0.834757</td>\n",
       "      <td>-0.037087</td>\n",
       "      <td>0.670067</td>\n",
       "      <td>1.265826</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.142506</td>\n",
       "      <td>-0.297806</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>0.203106</td>\n",
       "      <td>0.321248</td>\n",
       "      <td>0.284305</td>\n",
       "      <td>-0.870200</td>\n",
       "      <td>-0.023509</td>\n",
       "      <td>-0.779671</td>\n",
       "      <td>0.256113</td>\n",
       "      <td>-0.142984</td>\n",
       "      <td>-0.125783</td>\n",
       "      <td>0.613579</td>\n",
       "      <td>-0.664531</td>\n",
       "      <td>-0.361316</td>\n",
       "      <td>0.632411</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.368229</td>\n",
       "      <td>0.100094</td>\n",
       "      <td>-0.451423</td>\n",
       "      <td>0.119399</td>\n",
       "      <td>0.713166</td>\n",
       "      <td>-0.124793</td>\n",
       "      <td>-0.141202</td>\n",
       "      <td>0.422463</td>\n",
       "      <td>-1.221266</td>\n",
       "      <td>-0.518500</td>\n",
       "      <td>-1.331652</td>\n",
       "      <td>-0.536614</td>\n",
       "      <td>-0.127441</td>\n",
       "      <td>-1.004657</td>\n",
       "      <td>-0.881143</td>\n",
       "      <td>0.579444</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>-0.226262</td>\n",
       "      <td>-0.500569</td>\n",
       "      <td>-0.775275</td>\n",
       "      <td>-0.361730</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>0.162621</td>\n",
       "      <td>-0.664219</td>\n",
       "      <td>-0.001546</td>\n",
       "      <td>-0.566167</td>\n",
       "      <td>0.231011</td>\n",
       "      <td>-1.071825</td>\n",
       "      <td>-1.086434</td>\n",
       "      <td>0.167880</td>\n",
       "      <td>-0.505737</td>\n",
       "      <td>-1.246956</td>\n",
       "      <td>-0.019074</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>-0.730689</td>\n",
       "      <td>-0.450749</td>\n",
       "      <td>-1.475323</td>\n",
       "      <td>-0.406076</td>\n",
       "      <td>-0.070954</td>\n",
       "      <td>-0.605523</td>\n",
       "      <td>-1.163639</td>\n",
       "      <td>-0.891475</td>\n",
       "      <td>0.143619</td>\n",
       "      <td>-0.258749</td>\n",
       "      <td>0.137435</td>\n",
       "      <td>-0.855798</td>\n",
       "      <td>1.017545</td>\n",
       "      <td>0.523758</td>\n",
       "      <td>-0.736648</td>\n",
       "      <td>-0.058714</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    delta-TP9 delta-AF7 delta-AF8 delta-TP10 theta-TP9 theta-AF7 theta-AF8  \\\n",
       "0    0.213514  2.399008  2.407957   0.393249  0.534341  0.836858  1.424246   \n",
       "1    0.274502  0.921714  1.514658   0.496492  0.181557 -0.012250  0.626624   \n",
       "2    0.069119  0.729497  1.285416   0.097301 -0.467740  0.760934 -0.579900   \n",
       "3    0.003141  0.480663  1.615700  -0.158431 -1.007132  1.443319 -0.212008   \n",
       "4   -0.210349  0.119917  1.832329  -0.231751 -0.616393  1.045143 -0.127250   \n",
       "5   -0.051825 -0.263452  1.119956  -0.327761 -0.505222  0.152652 -0.513246   \n",
       "6    0.086974 -0.671780  1.001618  -0.122757 -0.682590  0.430467 -1.075897   \n",
       "7   -0.480012 -2.006218 -0.028464  -0.295416 -0.538043 -0.236132 -1.324888   \n",
       "8   -0.405463 -1.644300 -0.270670  -0.242053 -0.017734 -0.174221 -0.019164   \n",
       "9   -0.432286 -0.152718  0.598483  -0.115877  0.133831  0.401195  0.130803   \n",
       "10   0.146932  0.235146  0.294602  -0.572148  0.227806  0.450138 -0.279869   \n",
       "11  -0.001430  0.866532  0.744292  -0.797730  0.307789  0.860581  0.251318   \n",
       "12   0.146348  0.618151  0.610340  -1.154899  0.408110  1.329480 -0.001540   \n",
       "13  -0.103998  0.263626  0.236944  -1.133041 -0.145694  1.157310 -0.794460   \n",
       "14  -0.067884  0.280909 -0.006766  -0.396238 -0.612612  1.093421 -0.599752   \n",
       "15  -0.108029  0.704948 -0.516454  -0.054405 -0.911179  1.046748 -0.381751   \n",
       "16  -0.128855  1.362195 -0.057506  -0.074408 -0.622653  0.050969 -0.896629   \n",
       "17   0.128464  0.859343 -0.277063  -0.139770 -0.014030 -1.118520 -1.396692   \n",
       "18  -0.229944  0.571342 -1.075829  -0.474831 -0.224679 -0.372622 -0.752135   \n",
       "19  -0.220150 -1.361181 -1.257925  -0.341096 -0.829263 -0.094745 -0.332439   \n",
       "20  -0.075262 -1.554477 -1.113769  -0.527430 -0.603400 -0.548110 -0.618227   \n",
       "21   0.106924 -0.965343  0.072309  -0.694574 -0.562903 -0.930546  0.135469   \n",
       "22  -0.172397 -0.708051  0.153175  -0.907947 -0.338745 -0.474828  0.361558   \n",
       "23  -0.150760  0.466819  1.005948  -0.083369 -0.541209 -0.134129 -0.035947   \n",
       "24  -0.579743  0.633773  1.026589  -0.183963 -0.686479  0.085274 -0.472252   \n",
       "25  -0.625463  0.653343  0.373161  -0.315085 -0.848928  0.607960 -0.466801   \n",
       "26  -0.229980  0.352520  0.886853  -0.498656 -0.871644  0.715199  0.448787   \n",
       "27   0.013421  0.177602  0.404552  -0.067575 -0.339092  0.660191  0.277448   \n",
       "28  -0.146794 -0.060504  1.289442  -0.208396  0.205269  0.316208  0.454721   \n",
       "29   0.154859 -0.354284  1.067686   0.158146  0.008562  0.152232  0.288690   \n",
       "..        ...       ...       ...        ...       ...       ...       ...   \n",
       "262 -0.751458 -0.610216 -0.161276   0.036396  0.000733 -1.206478  0.162563   \n",
       "263 -0.633193 -1.122481 -0.054847  -0.360719  0.378721 -0.837366 -0.600157   \n",
       "264 -0.392653 -0.737491 -0.500402  -0.281268 -0.115444 -0.229041  0.434597   \n",
       "265 -0.716079 -1.022264 -0.858400  -0.395495  0.184340  0.377695  0.415141   \n",
       "266 -1.267904 -0.641252 -1.454673  -0.321021  0.640080  0.177762 -0.083836   \n",
       "267 -0.631198 -0.423214 -1.315832  -0.376819  0.288431 -0.220710  0.014223   \n",
       "268 -0.267619 -0.688307 -0.984739  -0.343621 -0.677592  0.419800  0.554753   \n",
       "269 -0.423743 -0.571219 -0.358224  -0.210009 -0.184537  0.856991  0.393675   \n",
       "270 -0.565201 -0.112536  0.134301  -0.384410 -0.182179  0.970412 -0.312539   \n",
       "271 -0.735997 -0.008424  0.000144  -0.733817 -0.362947  0.519772  0.063147   \n",
       "272 -0.488950  0.099833  0.629765  -0.661423  0.003037  0.037508  0.056930   \n",
       "273 -0.518196 -0.609915  0.476455  -1.141158  0.098360  0.229413 -0.851217   \n",
       "274 -1.091459 -0.532345  0.494349  -0.352449 -0.015291 -0.566431 -0.504227   \n",
       "275 -0.830376 -0.220333  0.225104  -0.222778  0.542507 -0.173958 -1.610090   \n",
       "276 -0.591421  0.043669  0.161249  -0.395154  0.125585  0.527319 -1.837182   \n",
       "277 -0.320731 -0.347213 -0.457326  -0.301098 -0.515956  0.049768 -1.414502   \n",
       "278 -0.193964 -1.317364 -1.177051   0.064863  0.942513 -0.935262 -2.685323   \n",
       "279  0.484398 -1.298334 -1.466594   0.728681  1.544378 -1.503549 -2.920800   \n",
       "280  0.331313 -0.964134 -1.258116   0.445556  1.033292 -1.011368 -2.479521   \n",
       "281 -0.334840 -0.865352 -0.432529   0.030444  0.434598  0.034882 -1.721293   \n",
       "282 -0.818510 -0.752782 -0.511477  -0.888362  0.341487  0.283600 -1.538431   \n",
       "283 -0.467644 -0.759969 -0.463293  -0.876372  0.032144 -0.257510 -1.388784   \n",
       "284 -0.062382 -0.473620 -0.988784  -0.413188  0.335930 -0.407431 -0.477790   \n",
       "285  0.304108 -0.219053 -1.497537  -0.465347 -0.070486 -0.741291 -0.004767   \n",
       "286  0.069618 -0.669605 -0.522444  -0.012146 -0.102132  0.009599  0.071879   \n",
       "287  0.621599  0.128548  0.041879   0.235494 -0.174439  0.663040 -0.854652   \n",
       "288  0.142506 -0.297806  0.005136   0.203106  0.321248  0.284305 -0.870200   \n",
       "289  0.368229  0.100094 -0.451423   0.119399  0.713166 -0.124793 -0.141202   \n",
       "290 -0.226262 -0.500569 -0.775275  -0.361730  0.332600  0.162621 -0.664219   \n",
       "291 -0.730689 -0.450749 -1.475323  -0.406076 -0.070954 -0.605523 -1.163639   \n",
       "\n",
       "    theta-TP10 alpha-TP9 alpha-AF7 alpha-AF8 alpha-TP10  beta-TP9  beta-AF7  \\\n",
       "0     0.657038 -0.467993  0.814466  0.643818   0.098162 -1.078152  0.973413   \n",
       "1     0.175984 -0.906638  0.832131 -0.332070   0.329700 -1.247669 -0.714387   \n",
       "2    -0.558739 -1.301238 -0.218394 -0.055393   0.249293 -1.385920  0.074558   \n",
       "3    -0.532355 -1.779209 -1.227202  0.353502  -0.087381 -0.508575 -0.075375   \n",
       "4    -0.344241 -1.137883 -1.686370  0.923469  -0.147632  0.351424 -1.111880   \n",
       "5    -0.258107 -0.828238 -1.597773  0.385438  -0.313688  0.287174 -1.351710   \n",
       "6    -0.075021 -0.448091 -0.746614 -0.298868  -0.503815 -0.541788 -0.272356   \n",
       "7    -0.092515 -0.013630  0.435665 -0.533208   0.143743 -1.518596  0.596153   \n",
       "8     0.089024  0.491391  0.228489  0.077964   0.502514 -1.016791  0.695858   \n",
       "9     0.122528  0.354565  0.811382  0.698648  -0.230683 -0.320636  0.151858   \n",
       "10   -0.306065 -0.867224  1.252146  0.535048  -0.178032  0.251012 -0.823283   \n",
       "11   -0.248140 -0.017924  0.818161  0.089419   1.150737  0.138925 -1.311787   \n",
       "12   -0.439488 -0.033736  0.732197 -0.102318   1.281039 -0.735398 -1.222797   \n",
       "13   -0.143984 -0.082622  0.288880 -1.421855   0.213885 -0.590549 -0.155423   \n",
       "14   -0.686979  0.392291  0.917120 -1.160279   0.423007  0.201738  1.077944   \n",
       "15   -1.299481  0.029613  2.266867  0.265729   0.369297 -0.149129  1.494485   \n",
       "16   -1.056867 -1.398627  1.957782  0.166856   0.286042 -1.065816  1.250892   \n",
       "17   -0.653213 -1.812951 -0.149790 -1.393145  -0.022676 -0.881834  1.114260   \n",
       "18   -0.190520 -0.215686 -1.686898 -1.489736  -0.632539 -1.158338  2.159359   \n",
       "19   -0.151970  0.291878 -0.286571  0.022930   0.051437 -1.255987  0.972860   \n",
       "20   -0.367569 -0.581791  0.071743  0.909140   0.359319 -0.197760 -1.543971   \n",
       "21   -0.955379 -0.008098  0.496828  1.026037   1.101956 -0.671572 -1.541274   \n",
       "22   -0.940465  0.079976  0.722999  0.025365   0.743568 -1.218136 -1.856360   \n",
       "23   -0.738934 -1.288300  0.929868 -0.454915  -0.920439 -0.581734 -0.100377   \n",
       "24   -0.456016 -2.446710  0.798586 -0.958334  -1.870411  0.279462  0.605390   \n",
       "25   -1.059609 -0.521059  0.761648  0.173717  -1.706728  0.367991  0.392148   \n",
       "26   -1.945200  0.094593 -1.020576  1.159258  -1.016866 -0.144165  0.521299   \n",
       "27   -0.652449  0.479082 -0.483437  1.976568  -0.396122 -0.991673  0.867033   \n",
       "28    0.051697  0.251493  1.052970  1.571304  -0.145694 -0.262660  0.340540   \n",
       "29    0.007871  0.067617  1.011340 -0.583221   0.537474  0.758452 -0.506645   \n",
       "..         ...       ...       ...       ...        ...       ...       ...   \n",
       "262  -0.253040  0.465269 -2.807787  0.206365  -1.635500  1.173014 -1.004578   \n",
       "263  -0.874927  0.581135 -1.802812 -0.115994  -1.835811  1.470226 -2.189751   \n",
       "264  -0.716015 -0.514144 -0.694647 -0.963604  -1.169185  0.071527 -0.187068   \n",
       "265  -0.030307 -0.092597  0.469911 -0.931781   0.173419 -1.497404 -0.161618   \n",
       "266   0.453797  0.252103  0.915598 -0.265297   0.129005 -0.427761  0.791337   \n",
       "267  -0.182441  0.727881  1.238689  1.192414  -0.728431  0.619864  1.545326   \n",
       "268  -0.437086  0.915015  1.319920  1.392516  -0.732860  0.813330  1.301755   \n",
       "269   0.288659  0.194818  0.041240  0.929745  -1.065491  0.084643 -0.063926   \n",
       "270   0.090177  0.151709  0.319037  0.305943  -0.635190 -0.113333  0.391727   \n",
       "271  -0.143916  0.217183  1.340800  1.293519  -0.936617 -0.280943  1.053654   \n",
       "272   0.214998  0.707054  1.571159  1.193769  -1.355068  0.331677  1.429783   \n",
       "273  -0.230176  0.703755  1.049569 -0.488490  -0.225198  0.852984  1.503196   \n",
       "274  -0.401922  0.428411 -0.727007 -1.680978   0.876752  1.127848  0.672176   \n",
       "275   0.022923  0.441008  1.088264 -0.512342   1.155613  1.460273  0.985298   \n",
       "276  -0.506985 -0.353646  1.831691  1.260005   0.261513  1.937831  1.790504   \n",
       "277  -0.508958  0.834722  0.700527  1.211059   0.277951  0.832158  0.909237   \n",
       "278   0.517734  1.234924 -0.060353  0.413310   0.605364  1.397067  0.396437   \n",
       "279   1.127777  1.366370  0.266824  1.281940   1.333339  2.040250 -0.863296   \n",
       "280   0.734708  0.748035 -0.465168  1.254991   0.606407  1.233160 -2.348730   \n",
       "281   0.236212 -0.269558 -0.609350  0.965859  -1.018153 -0.460573 -1.926787   \n",
       "282   0.001672  0.007345 -0.611236  0.465059   0.517533 -0.571996 -0.251092   \n",
       "283  -0.875743  0.170356 -0.553645 -0.020402   0.858159 -0.055794 -0.179972   \n",
       "284  -0.902575 -0.223979  0.821292  0.814628  -0.289759 -0.220196 -1.485033   \n",
       "285  -1.349954  0.323032  1.647187  0.873026  -1.011018 -0.118026 -1.016163   \n",
       "286  -0.952852  0.020400  1.286663  0.226334  -0.055925  0.369780  0.039462   \n",
       "287  -0.458620 -0.026204  1.155755  0.849255   0.313060  0.834757 -0.037087   \n",
       "288  -0.023509 -0.779671  0.256113 -0.142984  -0.125783  0.613579 -0.664531   \n",
       "289   0.422463 -1.221266 -0.518500 -1.331652  -0.536614 -0.127441 -1.004657   \n",
       "290  -0.001546 -0.566167  0.231011 -1.071825  -1.086434  0.167880 -0.505737   \n",
       "291  -0.891475  0.143619 -0.258749  0.137435  -0.855798  1.017545  0.523758   \n",
       "\n",
       "     beta-AF8 beta-TP10 Label  \n",
       "0   -0.246633 -0.845306   0.0  \n",
       "1   -1.326559 -1.020843   0.0  \n",
       "2   -1.289886 -0.749937   0.0  \n",
       "3   -0.891891 -0.433480   0.0  \n",
       "4   -1.395548 -0.580706   0.0  \n",
       "5   -2.052439 -0.951017   0.0  \n",
       "6   -1.350803 -1.294469   0.0  \n",
       "7   -0.822614 -0.923277   0.0  \n",
       "8   -1.372176 -0.801689   0.0  \n",
       "9   -1.347009 -1.015522   0.0  \n",
       "10  -1.439193 -0.262769   0.0  \n",
       "11  -2.067773  0.070253   0.0  \n",
       "12  -1.239380  0.090161   0.0  \n",
       "13  -0.409051  0.137500   0.0  \n",
       "14  -1.138245 -0.058830   0.0  \n",
       "15  -0.851704 -0.349241   0.0  \n",
       "16  -1.077530 -0.409245   0.0  \n",
       "17  -3.526155 -1.025142   0.0  \n",
       "18  -2.899488 -0.871926   0.0  \n",
       "19  -1.483333 -0.529287   0.0  \n",
       "20  -2.134971 -0.322525   0.0  \n",
       "21  -3.062097 -0.833115   0.0  \n",
       "22  -2.510667 -1.003153   0.0  \n",
       "23  -1.511623 -0.889891   0.0  \n",
       "24  -0.612778 -0.072402   0.0  \n",
       "25  -0.373201  0.166671   0.0  \n",
       "26  -0.527413 -0.388440   0.0  \n",
       "27   0.318450 -0.103488   0.0  \n",
       "28   0.943424 -0.259735   0.0  \n",
       "29  -0.312422 -0.031583   0.0  \n",
       "..        ...       ...   ...  \n",
       "262  0.387729  1.224671   1.0  \n",
       "263  0.670324  0.553364   1.0  \n",
       "264  1.086861  0.740411   1.0  \n",
       "265  0.248853  0.413739   1.0  \n",
       "266 -0.731442 -0.645931   1.0  \n",
       "267 -1.509833 -0.544240   1.0  \n",
       "268 -1.520715 -0.786434   1.0  \n",
       "269 -1.446977 -0.889520   1.0  \n",
       "270 -0.715345 -0.164591   1.0  \n",
       "271 -0.230961  1.294397   1.0  \n",
       "272  0.148198  1.648714   1.0  \n",
       "273 -0.274591  0.510139   1.0  \n",
       "274 -0.247189 -0.062704   1.0  \n",
       "275  0.553466  1.659895   1.0  \n",
       "276  0.664807  2.528723   1.0  \n",
       "277  0.782942  1.324878   1.0  \n",
       "278  1.182025  0.612418   1.0  \n",
       "279  1.339852  1.471146   1.0  \n",
       "280  0.315625  0.996471   1.0  \n",
       "281  0.220132 -0.251230   1.0  \n",
       "282 -0.023257 -0.094554   1.0  \n",
       "283  0.517955  0.538673   1.0  \n",
       "284  1.194371  0.428822   1.0  \n",
       "285  1.827988  0.517917   1.0  \n",
       "286  1.810562  1.015129   1.0  \n",
       "287  0.670067  1.265826   1.0  \n",
       "288 -0.361316  0.632411   1.0  \n",
       "289 -0.881143  0.579444   1.0  \n",
       "290 -1.246956 -0.019074   1.0  \n",
       "291 -0.736648 -0.058714   1.0  \n",
       "\n",
       "[292 rows x 17 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about not normalizing and centering for RF\n",
    "\n",
    "Let's see if neural can be a bit better for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.torch_imports import *\n",
    "from fastai.io import *\n",
    "from fastai.metrics import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(1*16, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 2),\n",
    "    nn.LogSoftmax()\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/EEG'\n",
    "md = ImageClassifierData.from_arrays(path, (X_train,y_train), (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=nn.NLLLoss()\n",
    "metrics=[accuracy]\n",
    "# opt=optim.SGD(net.parameters(), 1e-1, momentum=0.9)\n",
    "opt=optim.SGD(net.parameters(), 1e-1, momentum=0.9, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_loss(y, p):\n",
    "    return np.mean(-(y * np.log(p) + (1-y)*np.log(1-p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d43faec310e4e9ba90c46d6219d4760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "145",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\fastai\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2601\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2602\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2603\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 145",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-4d27984296a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\fastai\\courses\\ml1\\fastai\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mall_val\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIterBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\fastai\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1000\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m   1001\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1003\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\fastai\\courses\\ml1\\fastai\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[1;31m# avoid py3.6 issue where queue is infinite and can result in memory exhaustion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunk_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_sampler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mget_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\fastai\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    584\u001b[0m                     \u001b[1;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\fastai\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    423\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\fastai\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\fastai\\lib\\concurrent\\futures\\thread.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\fastai\\courses\\ml1\\fastai\\dataloader.py\u001b[0m in \u001b[0;36mget_batch\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose_y\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\fastai\\courses\\ml1\\fastai\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose_y\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\fastai\\courses\\ml1\\fastai\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget1item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget1item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\fastai\\courses\\ml1\\fastai\\dataset.py\u001b[0m in \u001b[0;36mget1item\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget1item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\fastai\\courses\\ml1\\fastai\\dataset.py\u001b[0m in \u001b[0;36mget_x\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mget_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\fastai\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2915\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2916\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2917\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2918\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2919\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\fastai\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2602\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2603\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2604\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2605\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2606\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 145"
     ]
    }
   ],
   "source": [
    "fit(net, md, n_epochs=5, crit=loss, opt=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
